<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>üéôÔ∏è Voice Assistant</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%);
            color: #e4e4e4;
            min-height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            padding: 20px;
        }

        .container {
            max-width: 600px;
            width: 100%;
            background: rgba(30, 30, 46, 0.95);
            border-radius: 20px;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.5);
            overflow: hidden;
        }

        .header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            padding: 30px;
            text-align: center;
        }

        .header h1 {
            font-size: 2em;
            margin-bottom: 10px;
        }

        .status {
            display: inline-flex;
            align-items: center;
            gap: 8px;
            padding: 8px 16px;
            background: rgba(255, 255, 255, 0.2);
            border-radius: 20px;
            font-size: 0.9em;
        }

        .status-dot {
            width: 10px;
            height: 10px;
            border-radius: 50%;
            background: #4ade80;
            animation: pulse 2s infinite;
        }

        @keyframes pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.5; }
        }

        .main-content {
            padding: 30px;
        }

        .instructions {
            background: rgba(74, 222, 128, 0.1);
            border-left: 4px solid #4ade80;
            padding: 20px;
            border-radius: 10px;
            margin-bottom: 30px;
        }

        .instructions h3 {
            color: #4ade80;
            margin-bottom: 15px;
        }

        .instructions ol {
            margin-left: 20px;
        }

        .instructions li {
            margin-bottom: 8px;
            line-height: 1.6;
        }

        .mic-container {
            text-align: center;
            margin: 40px 0;
        }

        .mic-button {
            width: 150px;
            height: 150px;
            border-radius: 50%;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            border: none;
            cursor: pointer;
            display: inline-flex;
            align-items: center;
            justify-content: center;
            font-size: 4em;
            transition: all 0.3s ease;
            box-shadow: 0 10px 30px rgba(102, 126, 234, 0.3);
        }

        .mic-button:hover:not(:disabled) {
            transform: scale(1.05);
            box-shadow: 0 15px 40px rgba(102, 126, 234, 0.5);
        }

        .mic-button:active:not(:disabled) {
            transform: scale(0.95);
        }

        .mic-button:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }

        .mic-button.recording {
            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
            animation: recording-pulse 1.5s infinite;
        }

        @keyframes recording-pulse {
            0%, 100% {
                box-shadow: 0 0 0 0 rgba(245, 87, 108, 0.7);
            }
            50% {
                box-shadow: 0 0 0 20px rgba(245, 87, 108, 0);
            }
        }

        .mic-instruction {
            margin-top: 20px;
            font-size: 1.1em;
            color: #a0aec0;
        }

        .end-button {
            width: 100%;
            padding: 15px;
            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
            color: white;
            border: none;
            border-radius: 12px;
            font-size: 1.1em;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s ease;
            margin-bottom: 20px;
        }

        .end-button:hover:not(:disabled) {
            transform: translateY(-2px);
            box-shadow: 0 5px 20px rgba(245, 87, 108, 0.4);
        }

        .end-button:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }

        .conversation-box {
            background: rgba(20, 20, 30, 0.6);
            border-radius: 15px;
            padding: 20px;
            max-height: 300px;
            overflow-y: auto;
            margin-bottom: 20px;
            border: 1px solid rgba(102, 126, 234, 0.3);
        }

        .message {
            margin-bottom: 15px;
            padding: 12px 18px;
            border-radius: 12px;
            animation: slideIn 0.3s ease;
        }

        @keyframes slideIn {
            from {
                opacity: 0;
                transform: translateY(10px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        .message.user {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            margin-left: 20%;
        }

        .message.assistant {
            background: rgba(102, 126, 234, 0.2);
            border: 1px solid rgba(102, 126, 234, 0.3);
            margin-right: 20%;
        }

        .message-label {
            font-size: 0.75em;
            opacity: 0.7;
            margin-bottom: 5px;
            font-weight: 600;
        }

        .conversation-box::-webkit-scrollbar {
            width: 8px;
        }

        .conversation-box::-webkit-scrollbar-track {
            background: rgba(20, 20, 30, 0.6);
            border-radius: 10px;
        }

        .conversation-box::-webkit-scrollbar-thumb {
            background: rgba(102, 126, 234, 0.5);
            border-radius: 10px;
        }

        .history-section {
            margin-top: 20px;
            padding-top: 20px;
            border-top: 1px solid rgba(102, 126, 234, 0.3);
        }

        .history-section h3 {
            margin-bottom: 15px;
            color: #667eea;
        }

        .history-item {
            background: rgba(20, 20, 30, 0.6);
            padding: 15px;
            border-radius: 10px;
            margin-bottom: 10px;
            display: flex;
            justify-content: space-between;
            align-items: center;
            border: 1px solid rgba(102, 126, 234, 0.2);
        }

        .history-info {
            flex: 1;
        }

        .btn-small {
            padding: 8px 15px;
            font-size: 0.85em;
            background: rgba(102, 126, 234, 0.3);
            color: #e4e4e4;
            border: none;
            border-radius: 8px;
            cursor: pointer;
            transition: all 0.3s ease;
        }

        .btn-small:hover {
            background: rgba(102, 126, 234, 0.5);
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>üéôÔ∏è Voice Assistant</h1>
            <div class="status">
                <div class="status-dot"></div>
                <span id="statusText">Ready</span>
            </div>
        </div>

        <div class="main-content">
            <div class="instructions">
                <h3>Instructions:</h3>
                <ol>
                    <li>Click "Start Conversation" to begin</li>
                    <li>Press and hold the microphone to speak</li>
                    <li>Release to send your message</li>
                    <li>Click "End Conversation" to save and exit</li>
                </ol>
            </div>

            <div class="conversation-box" id="conversationBox">
                <div class="message assistant">
                    <div class="message-label">Assistant</div>
                    <div>Click "Start Conversation" to begin</div>
                </div>
            </div>

            <button class="end-button" id="endBtn" onclick="endConversation()" disabled>
                END CONVERSATION
            </button>

            <div class="mic-container">
                <button class="mic-button" id="micBtn" disabled>
                    üé§
                </button>
                <div class="mic-instruction">Press and hold to speak</div>
            </div>

            <div class="history-section">
                <h3>üìã Conversation History</h3>
                <div id="historyList"></div>
            </div>
        </div>
    </div>

    <script>
        let ws = null;
        let currentSessionId = null;
        let isRecording = false;
        let audioContext;
        let sourceNode;
        let processor;
        let recordedChunks = [];
        let stream;

        function updateStatus(message) {
            document.getElementById('statusText').textContent = message;
        }

        function addMessage(role, content) {
            const box = document.getElementById('conversationBox');
            const msgDiv = document.createElement('div');
            msgDiv.className = `message ${role}`;
            msgDiv.innerHTML = `
                <div class="message-label">${role === 'user' ? 'You' : 'Assistant'}</div>
                <div>${content}</div>
            `;
            box.appendChild(msgDiv);
            box.scrollTop = box.scrollHeight;
        }

        async function startConversation() {
            try {
                // Request microphone permission first
                stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                stream.getTracks().forEach(track => track.stop());
                
                ws = new WebSocket(`ws://127.0.0.1:8000/ws/voice`);
                
                ws.onopen = () => {
                    updateStatus('Connected');
                    document.getElementById('micBtn').disabled = false;
                    document.getElementById('endBtn').disabled = false;
                    document.querySelector('.instructions').style.display = 'none';
                };

                ws.onmessage = async (event) => {
                    const data = JSON.parse(event.data);
                    
                    if (data.type === 'session_start') {
                        currentSessionId = data.session_id;
                        updateStatus(`Session: ${currentSessionId}`);
                    }
                    
                    if (data.type === 'audio') {
                        addMessage('assistant', data.text);
                        await playAudio(data.data);
                    }
                    
                    if (data.type === 'transcription') {
                        addMessage(data.role, data.text);
                    }
                    
                    if (data.type === 'error') {
                        addMessage('assistant', data.message);
                    }
                };

                ws.onerror = (error) => {
                    console.error('WebSocket error:', error);
                    updateStatus('Connection error');
                };

                ws.onclose = () => {
                    updateStatus('Disconnected');
                    document.getElementById('micBtn').disabled = true;
                    document.getElementById('endBtn').disabled = true;
                    loadHistory();
                };

            } catch (error) {
                console.error('Failed to start:', error);
                alert('Please allow microphone access');
            }
        }

        async function startRecording() {
            try {
                stream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        channelCount: 1,
                        sampleRate: 16000,
                        echoCancellation: true,
                        noiseSuppression: true
                    } 
                });
                
                audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 16000 });
                sourceNode = audioContext.createMediaStreamSource(stream);
                
                processor = audioContext.createScriptProcessor(4096, 1, 1);
                recordedChunks = [];
                
                processor.onaudioprocess = (e) => {
                    const inputData = e.inputBuffer.getChannelData(0);
                    recordedChunks.push(new Float32Array(inputData));
                };
                
                sourceNode.connect(processor);
                processor.connect(audioContext.destination);
                
                isRecording = true;
                document.getElementById('micBtn').classList.add('recording');
                updateStatus('Recording...');

            } catch (error) {
                console.error('Recording error:', error);
                alert('Microphone access denied');
            }
        }

        async function stopRecording() {
            if (!isRecording) return;
            
            isRecording = false;
            document.getElementById('micBtn').classList.remove('recording');
            updateStatus('Processing...');
            
            if (processor) {
                processor.disconnect();
                sourceNode.disconnect();
            }
            
            if (stream) {
                stream.getTracks().forEach(track => track.stop());
            }
            
            if (audioContext) {
                audioContext.close();
                
                const wavBlob = createWavBlob(recordedChunks, 16000);
                
                if (wavBlob.size < 1000) {
                    updateStatus('Recording too short');
                    return;
                }
                
                const reader = new FileReader();
                reader.onloadend = () => {
                    const base64Audio = reader.result.split(',')[1];
                    if (ws && ws.readyState === WebSocket.OPEN) {
                        ws.send(JSON.stringify({
                            type: 'audio',
                            data: base64Audio
                        }));
                    }
                };
                reader.readAsDataURL(wavBlob);
            }
        }
        
        function createWavBlob(audioChunks, sampleRate) {
            const length = audioChunks.reduce((acc, chunk) => acc + chunk.length, 0);
            const audioData = new Float32Array(length);
            let offset = 0;
            
            for (const chunk of audioChunks) {
                audioData.set(chunk, offset);
                offset += chunk.length;
            }
            
            const pcmData = new Int16Array(audioData.length);
            for (let i = 0; i < audioData.length; i++) {
                const s = Math.max(-1, Math.min(1, audioData[i]));
                pcmData[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
            }
            
            const wavHeader = new ArrayBuffer(44);
            const view = new DataView(wavHeader);
            
            const writeString = (offset, string) => {
                for (let i = 0; i < string.length; i++) {
                    view.setUint8(offset + i, string.charCodeAt(i));
                }
            };
            
            writeString(0, 'RIFF');
            view.setUint32(4, 36 + pcmData.length * 2, true);
            writeString(8, 'WAVE');
            writeString(12, 'fmt ');
            view.setUint32(16, 16, true);
            view.setUint16(20, 1, true);
            view.setUint16(22, 1, true);
            view.setUint32(24, sampleRate, true);
            view.setUint32(28, sampleRate * 2, true);
            view.setUint16(32, 2, true);
            view.setUint16(34, 16, true);
            writeString(36, 'data');
            view.setUint32(40, pcmData.length * 2, true);
            
            return new Blob([wavHeader, pcmData.buffer], { type: 'audio/wav' });
        }

        async function playAudio(base64Audio) {
            const audioData = atob(base64Audio);
            const arrayBuffer = new Uint8Array(audioData.length);
            for (let i = 0; i < audioData.length; i++) {
                arrayBuffer[i] = audioData.charCodeAt(i);
            }
            
            const blob = new Blob([arrayBuffer], { type: 'audio/mpeg' });
            const url = URL.createObjectURL(blob);
            const audio = new Audio(url);
            
            audio.play();
            updateStatus('Assistant speaking...');
            
            audio.onended = () => {
                updateStatus('Ready to talk');
                URL.revokeObjectURL(url);
            };
        }

        function endConversation() {
            if (ws) {
                ws.send(JSON.stringify({ type: 'end_session' }));
                ws.close();
            }
        }

        async function loadHistory() {
            try {
                const response = await fetch('/api/conversations');
                const conversations = await response.json();
                
                const historyList = document.getElementById('historyList');
                historyList.innerHTML = '';
                
                conversations.reverse().forEach(conv => {
                    const item = document.createElement('div');
                    item.className = 'history-item';
                    
                    const date = new Date(conv.start_time);
                    item.innerHTML = `
                        <div class="history-info">
                            <strong>${conv.session_id}</strong>
                            <div style="font-size: 0.85em; opacity: 0.7;">
                                ${date.toLocaleString()} ‚Ä¢ ${conv.message_count} messages
                            </div>
                        </div>
                        <button class="btn-small" onclick="downloadAudio('${conv.session_id}')">
                            üéµ Download
                        </button>
                    `;
                    
                    historyList.appendChild(item);
                });
            } catch (error) {
                console.error('Failed to load history:', error);
            }
        }

        async function downloadAudio(sessionId) {
            try {
                const response = await fetch(`/api/download-audio/${sessionId}`);
                const blob = await response.blob();
                const url = window.URL.createObjectURL(blob);
                const a = document.createElement('a');
                a.href = url;
                a.download = `conversation_${sessionId}.mp3`;
                document.body.appendChild(a);
                a.click();
                window.URL.revokeObjectURL(url);
                document.body.removeChild(a);
            } catch (error) {
                alert('Failed to download audio');
            }
        }

        // Mic button handlers
        const micBtn = document.getElementById('micBtn');
        
        micBtn.addEventListener('mousedown', startRecording);
        micBtn.addEventListener('mouseup', stopRecording);
        micBtn.addEventListener('mouseleave', () => {
            if (isRecording) stopRecording();
        });
        
        micBtn.addEventListener('touchstart', (e) => {
            e.preventDefault();
            startRecording();
        });
        micBtn.addEventListener('touchend', (e) => {
            e.preventDefault();
            stopRecording();
        });

        // Auto-start on load
        window.onload = () => {
            startConversation();
            loadHistory();
        };
    </script>
</body>
</html>